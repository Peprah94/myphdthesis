n.burnin = 0,
n.thin = 1,
setSeed = TRUE,
samples=TRUE,
samplesAsCodaMCMC = TRUE,
summary = TRUE,
WAIC = FALSE))
load("estimates.RData")
inlanim$output
model = mcmcconf$model
## node list generation
targetAsScalar <- model$expandNodeNames(target, returnScalarComponents = TRUE)
calcNodes <- model$getDependencies(target)
targetAsScalar
calcNodes <- model$getDependencies(target)
calcNodes
calcNodesNoSelf <- model$getDependencies(target, self = FALSE)
isStochCalcNodesNoSelf <- model$isStoch(calcNodesNoSelf)   ## should be made faster
calcNodesNoSelfDeterm <- calcNodesNoSelf[!isStochCalcNodesNoSelf]
calcNodesNoSelfStoch <- calcNodesNoSelf[isStochCalcNodesNoSelf]
## numeric value generation
# d <- length(targetAsScalar)
expandTarget <- model$expandNodeNames(target)
expandTarget
d <- length(model$expandNodeNames(target))
dr <- length(targetAsScalar)/d
thetaVec <- rep(0,dr)
thetaVec1 <- rep(0,dr)
scaleVec         <- rep(scaleOriginal, d)
scaleVec1         <- rep(scaleOriginal, d)
timesRan         <- 0
timesRan1         <- 0
timesAcceptedVec <- rep(0, d)
timesAcceptedVec1 <- rep(0, d)
timesAdapted     <- 0
timesAdapted1     <- 0
optimalAR        <- 0.44
optimalAR1        <- 0.44
gamma1           <- 0
gamma2           <- 0
target <- expandTarget[1]
target1 <- expandTarget[2]
target2 <- expandTarget[1]
target1 <- expandTarget[2]
devtools::load_all(".")
inlanim = INLAWiNimDataGenerating(data = data_df,
code = code,
modelData = inla_data,
modelConstants = const,
modelInits = idm_inits,
fam = "nogaussian",
parametersToMonitor = c("omega"),
mcmcConfiguration =  list(n.chains = 1,
n.iterations = 50,
n.burnin = 0,
n.thin = 1,
setSeed = TRUE,
samples=TRUE,
samplesAsCodaMCMC = TRUE,
summary = TRUE,
WAIC = FALSE))
sampler_BASE <- nimble::nimbleFunctionVirtual(
name = 'sampler_BASE',
methods = list(
reset = function() { }
)
)
myRW_dirichlet <- myRW_dirichlet <- nimble::nimbleFunction(
name = 'myRW_dirichlet',
contains = sampler_BASE,
setup = function(model, mvSaved, target, control) {
## control list extraction
adaptive            <- extractControlElement(control, 'adaptive',            TRUE)
adaptInterval       <- extractControlElement(control, 'adaptInterval',       200)
adaptFactorExponent <- extractControlElement(control, 'adaptFactorExponent', 0.8)
scaleOriginal       <- extractControlElement(control, 'scale',               1)
## node list generation
targetAsScalar <- model$expandNodeNames(target, returnScalarComponents = TRUE)
calcNodes <- model$getDependencies(target)
calcNodesNoSelf <- model$getDependencies(target, self = FALSE)
isStochCalcNodesNoSelf <- model$isStoch(calcNodesNoSelf)   ## should be made faster
calcNodesNoSelfDeterm <- calcNodesNoSelf[!isStochCalcNodesNoSelf]
calcNodesNoSelfStoch <- calcNodesNoSelf[isStochCalcNodesNoSelf]
## numeric value generation
# d <- length(targetAsScalar)
expandTarget <- model$expandNodeNames(target)
d <- length(model$expandNodeNames(target))
dr <- length(targetAsScalar)/d
#  thetaVec         <- matrix(rep(0, d*dr), nrow = dr)
thetaVec <- rep(0,dr)
thetaVec1 <- rep(0,dr)
scaleVec         <- rep(scaleOriginal, d)
scaleVec1         <- rep(scaleOriginal, d)
timesRan         <- 0
timesRan1         <- 0
timesAcceptedVec <- rep(0, d)
timesAcceptedVec1 <- rep(0, d)
timesAdapted     <- 0
timesAdapted1     <- 0
optimalAR        <- 0.44
optimalAR1        <- 0.44
gamma1           <- 0
gamma2           <- 0
target2 <- expandTarget[1]
target1 <- expandTarget[2]
## checks
#if(length(model$expandNodeNames(target)) > 1)    stop('RW_dirichlet sampler only applies to one target node')
#if(model$getDistribution(target) != 'ddirch')    stop('can only use RW_dirichlet sampler for dirichlet distributions')
},
run = function() {
eldf <- model$calculateDiff(calcNodesNoSelf)
for(j in 1:dr){
if(j == 1){
if(thetaVec[1] == 0)   thetaVec <<- values(model, target2)   ## initialization
alphaVec <- model$getParam(target2, 'alpha')
for(i in 1:d) {
currentValue <- thetaVec[i]
propLogScale <- rnorm(1, mean = 0, sd = scaleVec[i])
propValue <- currentValue * exp(propLogScale)
if(propValue != 0) {
thetaVecProp <- thetaVec
thetaVecProp[i] <- propValue
values(model, target2) <<- thetaVecProp / sum(thetaVecProp)
logMHR <- alphaVec[i]*propLogScale + currentValue - propValue + eldf
jump <- decide(logMHR)
} else jump <- FALSE
if(adaptive & jump)   timesAcceptedVec[i] <<- timesAcceptedVec[i] + 1
if(jump) {
thetaVec <<- thetaVecProp
nimCopy(from = model, to = mvSaved, row = 1, nodes = target2, logProb = TRUE)
nimCopy(from = model, to = mvSaved, row = 1, nodes = calcNodesNoSelfDeterm, logProb = FALSE)
nimCopy(from = model, to = mvSaved, row = 1, nodes = calcNodesNoSelfStoch, logProbOnly = TRUE)
} else {
nimCopy(from = mvSaved, to = model, row = 1, nodes = target2, logProb = TRUE)
nimCopy(from = mvSaved, to = model, row = 1, nodes = calcNodesNoSelfDeterm, logProb = FALSE)
nimCopy(from = mvSaved, to = model, row = 1, nodes = calcNodesNoSelfStoch, logProbOnly = TRUE)
}
model$calculate(target)                                                             ## update target logProb
nimCopy(from = model, to = mvSaved, row = 1, nodes = target2, logProbOnly = TRUE)    ##
}
if(adaptive) {
timesRan <<- timesRan + 1
if(timesRan %% adaptInterval == 0) {
acceptanceRateVec <- timesAcceptedVec / timesRan
timesAdapted <<- timesAdapted + 1
gamma1 <<- 1/((timesAdapted + 3)^adaptFactorExponent)
adaptFactorVec <- exp(10 * gamma1 * (acceptanceRateVec - optimalAR))
scaleVec <<- scaleVec * adaptFactorVec
timesRan <<- 0
timesAcceptedVec <<- numeric(d, 0)
}
}
}
if(j ==2){
if(thetaVec1[1] == 0)   thetaVec1 <<- values(model, target1)   ## initialization
alphaVec <- model$getParam(target1, 'alpha')
for(i in 1:d) {
currentValue <- thetaVec1[i]
propLogScale <- rnorm(1, mean = 0, sd = scaleVec[i])
propValue <- currentValue * exp(propLogScale)
if(propValue != 0) {
thetaVecProp <- thetaVec1
thetaVecProp[i] <- propValue
values(model, target1) <<- thetaVecProp / sum(thetaVecProp)
logMHR <- alphaVec[i]*propLogScale + currentValue - propValue + eldf
jump <- decide(logMHR)
} else jump <- FALSE
if(adaptive & jump)   timesAcceptedVec1[i] <<- timesAcceptedVec1[i] + 1
if(jump) {
thetaVec <<- thetaVecProp
nimCopy(from = model, to = mvSaved, row = 1, nodes = target1, logProb = TRUE)
nimCopy(from = model, to = mvSaved, row = 1, nodes = calcNodesNoSelfDeterm, logProb = FALSE)
nimCopy(from = model, to = mvSaved, row = 1, nodes = calcNodesNoSelfStoch, logProbOnly = TRUE)
} else {
nimCopy(from = mvSaved, to = model, row = 1, nodes = target1, logProb = TRUE)
nimCopy(from = mvSaved, to = model, row = 1, nodes = calcNodesNoSelfDeterm, logProb = FALSE)
nimCopy(from = mvSaved, to = model, row = 1, nodes = calcNodesNoSelfStoch, logProbOnly = TRUE)
}
model$calculate(target)                                                             ## update target logProb
nimCopy(from = model, to = mvSaved, row = 1, nodes = target1, logProbOnly = TRUE)    ##
}
if(adaptive) {
timesRan1 <<- timesRan + 1
if(timesRan %% adaptInterval == 0) {
acceptanceRateVec1 <- timesAcceptedVec1 / timesRan
timesAdapted1 <<- timesAdapted1 + 1
gamma2 <<- 1/((timesAdapted1 + 3)^adaptFactorExponent)
adaptFactorVec <- exp(10 * gamma1 * (acceptanceRateVec1 - optimalAR1))
scaleVec1 <<- scaleVec1 * adaptFactorVec
timesRan1 <<- 0
timesAcceptedVec1 <<- numeric(d, 0)
}
}
}
}
},
methods = list(
reset = function() {
thetaVec         <<- numeric(d, 0)
thetaVec1         <<- numeric(d, 0)
scaleVec         <<- numeric(d, scaleOriginal)
scaleVec1         <<- numeric(d, scaleOriginal)
timesRan         <<- 0
timesRan1         <<- 0
timesAcceptedVec <<- numeric(d, 0)
timesAcceptedVec1 <<- numeric(d, 0)
timesAdapted     <<- 0
timesAdapted1     <<- 0
gamma1           <<- 0
gamma2           <<- 0
}
)
)
assign('myRW_dirichlet', myRW_dirichlet, envir = .GlobalEnv)
dmydirch <- nimble::nimbleFunction(
run = function(x = double(1), alpha = double(1),
log = integer(0, default = 0)) {
returnType(double(0))
logProb <- sum(lgamma(alpha)) - lgamma(sum(alpha)) +
sum((alpha -1) * log(x))
if(log) return(logProb)
else return(exp(logProb))
})
rmydirch <- nimble::nimbleFunction(
run = function(n = integer(0), alpha = double(1)) {
returnType(double(1))
if(n != 1) print("rdirch only allows n = 1; using n = 1.")
p <- rdirch(1, alpha)
return(p)
})
inlanim = INLAWiNimDataGenerating(data = data_df,
code = code,
modelData = inla_data,
modelConstants = const,
modelInits = idm_inits,
fam = "nogaussian",
parametersToMonitor = c("omega"),
mcmcConfiguration =  list(n.chains = 1,
n.iterations = 5,
n.burnin = 0,
n.thin = 1,
setSeed = TRUE,
samples=TRUE,
samplesAsCodaMCMC = TRUE,
summary = TRUE,
WAIC = FALSE))
inlanim$output
inlanim$mcmc.out$summary
inlanim = INLAWiNimDataGenerating(data = data_df,
code = code,
modelData = inla_data,
modelConstants = const,
modelInits = idm_inits,
fam = "nogaussian",
parametersToMonitor = c("omega"),
mcmcConfiguration =  list(n.chains = 1,
n.iterations = 50,
n.burnin = 0,
n.thin = 1,
setSeed = TRUE,
samples=TRUE,
samplesAsCodaMCMC = TRUE,
summary = TRUE,
WAIC = FALSE))
inlanim$mcmc.out$summary
devtools::load_all(".")
cnt = 0
inlanim = INLAWiNimDataGenerating(data = data_df,
code = code,
modelData = inla_data,
modelConstants = const,
modelInits = idm_inits,
fam = "nogaussian",
parametersToMonitor = c("omega"),
mcmcConfiguration =  list(n.chains = 1,
n.iterations = 10,
n.burnin = 0,
n.thin = 1,
setSeed = TRUE,
samples=TRUE,
samplesAsCodaMCMC = TRUE,
summary = TRUE,
WAIC = FALSE))
# Running INLA within NIMBLE
cnt <- 0
listout <- list()
code <-nimbleCode({
for(i in 1:nspecies){
omega[i, 1:nspecies] ~ ddirch(alpha = alpha[1:nspecies])
}
r[1:nsite,1:20] <- nimbleINLADataGenerating(omega[1:nspecies,1:nspecies]) #change 38 to a constant to be specified
for(i in 1:nsite){
# for(j in 1:nspecies){
log(lambda_obs[i,1]) <- r[i,5] + r[i,6]*true_cov[i] + r[i,11]+
r[i, 7] + r[i,8]*bias_cov[i]+ r[i,12] - log(1+exp(r[i, 7] + r[i,8]*bias_cov[i]+ r[i,12])) +
r[i, 9] + r[i,10]*det_cov[i] - log(1+exp(r[i, 9] + r[i,10]*det_cov[i]))
# Second species
log(lambda_obs[i,2]) <- r[i,13] + r[i,14]*true_cov[i] + r[i,19]+
r[i, 15] + r[i,16]*bias_cov[i]+ r[i,20] - log(1+exp(r[i, 15] + r[i,16]*bias_cov[i]+ r[i,20])) +
r[i, 17] + r[i,18]*det_cov[i] - log(1+exp(r[i, 17] + r[i,18]*det_cov[i]))
}
lambda[1:nsite, 1:nspecies] <- lambda_obs[1:nsite, 1:nspecies]
#Proportion of lambdas
# Proportion for the multinomial distribution
for(site.tag in 1:nsite){
for(spe.tag in 1:nspecies){
prop[site.tag,spe.tag] <- (lambda[site.tag, spe.tag])/sum(lambda[site.tag, 1:nspecies])
}
}
# True data
for(site.tag in 1:nsite){
C[site.tag] ~ dcat(prop[site.tag,1:nspecies])
}
# Reported species
for(site.tag in 1:nsite){
Y[site.tag] ~ dcat(omega[C[site.tag],1:nspecies])
}
})
#Data
inla_data <- list(Y=data_df$Y,
C = data_df$C,
true_cov = data_df$eco_cov,
bias_cov=data_df$samp_cov,
det_cov= data_df$det_cov)
#Constants
const <- list(nspecies=length(unique(data_df$C)),
nsite = length(data_df$C),
alpha=rep(1, length(unique(data_df$C)))
)
# Initial values
idm_inits <- function(){list(omega = matrix(c(0.99, 0.01,
0.01, 0.99),
nrow=2, ncol=2, byrow = TRUE)
)
}
cnt = 0
inlanim = INLAWiNimDataGenerating(data = data_df,
code = code,
modelData = inla_data,
modelConstants = const,
modelInits = idm_inits,
fam = "nogaussian",
parametersToMonitor = c("omega"),
mcmcConfiguration =  list(n.chains = 1,
n.iterations = 5,
n.burnin = 0,
n.thin = 1,
setSeed = TRUE,
samples=TRUE,
samplesAsCodaMCMC = TRUE,
summary = TRUE,
WAIC = FALSE))
inlanim$mcmc.out$summary
library(myphdthesis)
library(myphdthesis)
startTime <- system.time()
startTime <- Sys.time()
startTime
entTime <- Sys.time()
endTime <- Sys.time()
timeTaken <- endTime - startTime
timeTaken
timeTaken <- as.numeric(endTime - startTime)
timeTaken
data("nhanes2")
library(myphdthesis)
data("nhanes2")
# Missing covariates
library(mice)
data(nhanes2)
devtools::load_all(".")
###########################
# DataGenerating process
###########################
library(spatstat)
library(maptools)
library(sp)
library(rgeos)
library(INLA)
library(dplyr)
library(raster)
library(pbapply)
library(reshape)
library(tiff)
library(maptools)
library(spatstat)
library(gdata)
library(ggplot2)
library(gridExtra)
#library(PCDSpline)
library(foreach)
library(doParallel)
library(viridis)
library(RandomFieldsUtils)
#library(devtools)
#install_github("cran/tiff")
require(devtools)
x0 <- seq(-1, 4, length = 100)
y0 <- seq(-1,4, length = 100)
gridlocs <- expand.grid(x0,y0)
# Covariates for true ecological state
gridcov <- outer(x0, y0, function(x,y) cos(x) - sin(y - 2))
covariate.im <- im(gridcov, x0, y0)
#Covariate for the sampling process
gridcov_thin <- outer(x0, y0, function(x,y) cos(2*x) - sin(2*y-4))
#gridcov_thin <- outer(x0, y0, function(x,y) cos(x) - sin(y - 2))
covariate_thin.im <- im(gridcov_thin, x0, y0)
#Covariate for the detection
gridcov_det <- outer(x0, y0, function(x,y) (x/2)^2+(y/2)^2)
covariate_detect.im <- im(gridcov_det, x0, y0)
# 2 species
nspecies <- 2#nspecies: Number of species we want to simulate
#input: List with the parameters of the model that generates CS data
input <-{list(
ecological = list(
fixed.effect=list(
intercept = c(0.8, 2.5 ),
betacov = c(1.5, -0.12)
),
hyperparameters = list(
sigma2 = c(0.2, 1.2),
range = c(1.2, 2.5)
)
),
sampling = list(
fixed.effect = list(
intercept = c(1.3),
betacov = c(-1.5)
),
hyperparameters=list(
sigma2 = c(0.2),
range = c(2.5)
)
),
detection = list(
fixed.effect = list(
intercept=c(2,-0.3),
betacov = c(-2, -0.5)
)
),
misclassification = list(
class_prob <- matrix(c(0.7, 0.3,
0.35, 0.65),
nrow=2, ncol=2, byrow = TRUE)
),
constants = list(n.species = 2,
seed= 1036610620 ),
plot = list(ecological= FALSE,
detection=FALSE,
sampling=FALSE,
all= FALSE,
classification=FALSE),
cov = list(covariate.im,
covariate_thin.im,
covariate_detect.im),
idxs = list(eco=c(1),
sampling=c(2),
detection=c(3))
)}
## Simulating the Covariates ##
simulateddata <- generateCSData(input)
nspecies = input$constants$n.species
devtools::load_all(".")
## Simulating the Covariates ##
simulateddata <- generateCSData(input)
nspecies = input$constants$n.species
## Covariates need to be in SpatialPixels format ##
#Covariates for true intensity
cov1.sp <- SpatialPointsDataFrame(coords = gridlocs,data = data.frame(cov=c(anti_t(rotate(rotate(covariate.im$v))))))
r <- raster(cov1.sp)
r1<-disaggregate(r, fact=res(r)/c(0.056,0.056))
cov1.rast <- rasterize(cov1.sp@coords,r1,cov1.sp$cov, fun=mean,na.rm=T)
cov1.spix <- as(cov1.rast,"SpatialPixelsDataFrame")
#Covariates for first thinning
cov2.sp <- SpatialPointsDataFrame(coords = gridlocs,data = data.frame(cov=c(anti_t(rotate(rotate(covariate_thin.im$v))))))
r <- raster(cov2.sp)
r1<-disaggregate(r, fact=res(r)/c(0.056,0.056))
cov2.rast <- rasterize(cov2.sp@coords,r1,cov2.sp$cov, fun=mean,na.rm=T)
cov2.spix <- as(cov2.rast,"SpatialPixelsDataFrame")
#Covariate for second thinning
cov3.sp <- SpatialPointsDataFrame(coords = gridlocs,data = data.frame(cov=c(anti_t(rotate(rotate(covariate_detect.im$v))))))
r <- raster(cov3.sp)
r1<-disaggregate(r, fact=res(r)/c(0.056,0.056))
cov3.rast <- rasterize(cov3.sp@coords,r1,cov3.sp$cov, fun=mean,na.rm=T)
cov3.spix <- as(cov3.rast,"SpatialPixelsDataFrame")
### Sampling the detections from a survey
rndpts_x0 <- runif(50, 0,3)
rndpts_y0 <- runif(50, 0,3)
rndpts <- data.frame(rndpts_x0, rndpts_y0)
det_prob <- list()
for(i in 1:nspecies){
rndpts_lin <- rndpts %>%
mutate(linpred = input$detection$fixed.effect$intercept[i] + input$detection$fixed.effect$betacov[i]* extract(cov3.rast,rndpts))
det_prob[[i]] <- plogis(rndpts_lin$linpred)
}
detection_data <- list()
for(i in 1:nspecies){
data_det <- vector("numeric", length(det_prob[[i]]))
for(j in 1:length(det_prob[[i]])){
data_det[j]<- rbinom(1,1, det_prob[[i]][j])
detection_data[[i]] <- data_det
}
}
#Organising as spatial dataframe
data_det_spframe <- list()
for(i in 1:nspecies){
data_det_spframe[[i]] <- SpatialPointsDataFrame(rndpts, data = data.frame(detection_data[[i]]))
names(data_det_spframe[[i]])<-paste0("detdata",i)
}
data_det_spframe
setwd("/Volumes/kwakupa-1/INLAWithinMCMC")
load("/Volumes/kwakupa-1/INLAWithinMCMC/BayesianLassoResults.RData")
